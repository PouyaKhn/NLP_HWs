{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "final-airline",
   "metadata": {},
   "source": [
    "\n",
    "<div dir=\"rtl\" align=\"right\"> \n",
    "\n",
    "     توجه: در این پروژه قرار است اطلاعات سایت Darooyab.ir استخراج شود و به دلیل اینکه این سایت درخواست های خارج از ایران را مسدود می‌کند، بنابراین این نوتبوک  را نمی‌توانید با گوگل کولب اجرا کنید و حتما باید روی کامپیوتر شخصی خود اجرا نمایید.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-softball",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    سایت گفته شده، یک سایت مرجع برای اطلاعات دارویی است که شامل حدود ۱۶۰۰ قلم دارو است. برای هر دارو دو نوع دسته بندی دارویی ذکر شده، اسم انگلیسی آن گفته شده و سپس توضیح های مختلفی ارائه شده است. قابل به ذکر است که توضیح های داروها قالب یکسانی ندارند یعنی ممکن است دارویی توضیح خاصی نداشته باشد اما داروی دیگر ۵۰ خط توضیح داشته باشد.\n",
    "    \n",
    "    ------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-petersburg",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    در ابتدا کتابخانه های مورد نیاز را فراخوانی میکنیم. تعدادی از کتابخانه ها هم نیاز به نصب دارند که قبل از فراخوانی آن‌ها، نصب را انجام میدهیم.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hazm --quiet\n",
    "!pip install nltk --quiet\n",
    "!pip install freqtools --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adjustable-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import codecs\n",
    "import tqdm\n",
    "import hazm\n",
    "import re\n",
    "import string\n",
    "import itertools\n",
    "import freqtools\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-nerve",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    برای استخراج داده از این سایت، از کتابخانه های Requests و BeautifulSoup استفاده میکنیم.\n",
    "    کتابخانه Request برای درخواست های HTTP Get و کتابخانه BeautifulSoup برای تجزیه اطلاعات HTML به کار میروند.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-canadian",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    در ابتدا آدرس پایه را تعریف کرده و سپس تمام اطلاعات آن صفحه را استخراج می‌کنیم. در سایت دارویاب، صفحه ای فهرست‌طور برای تمام دسته‌بندی های داروها وجود دارد. لذا این صفحه را به عنوان آدرس پایه استخراج میکنیم.\n",
    "    \n",
    "    سپس با تجزیه این صفحه، تمام لینک های درون آن را استخراج میکنیم که در حقیقت هر لینک، صفحه مربوط به یک دسته‌بندی خاص از دارو ها می‌باشد.\n",
    "    \n",
    "    حال به دلیل اینکه در هر صفحه لینک های متفرقه دیگری نیز وجود دارند که ما به آن‌ها نیاز نداریم، لذا با مشخص کردن یک الگوی زبان منظم، لینک هایی که مربوط به دسته‌بندی هستند را شناسایی و استخراج می‌کنیم و به دلیل اینکه از هر دسته ممکن است چند لینک موجود باشد، لینک های تکراری را نیز حذف میکنیم(با استفاده از تابع set)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "possible-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.darooyab.ir/DrugGroups'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text,'html.parser')\n",
    "\n",
    "links_pure = []\n",
    "for a in soup.find_all('a', href=True):\n",
    "    links_pure.append(a['href'])\n",
    "    \n",
    "pattern = re.compile(\"/DrugGroups/.*\")\n",
    "filtered_link = list(set(filter(pattern.match, links_pure)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-remove",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "    \n",
    "   تا اینجا ما لینک مربوط به هر دسته را داریم. لذا به تک تک لینک ها درخواست داده و صفحات آن‌ها را استخراج میکنیم و تمام اطلاعات را ذخیره می‌کنیم. حال تک تک صفحات را باز کرده و لینک های درون آن‌ها را استخراج می‌کنیم که در حقیقت لینک صفحات مربوط به دارو‌ها هستند. در اینجا نیز لینک های متفرقه را به وسیله زبان های منظم کنار گذاشته و لینک های تکراری دارو ها را نیز حذف می‌کنیم. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "constant-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'https://www.darooyab.ir'\n",
    "\n",
    "for i in range(len(filtered_link)):\n",
    "    filtered_link[i] = prefix + filtered_link[i]\n",
    "    \n",
    "links_pure = []\n",
    "for i in range(len(filtered_link)):\n",
    "    url = filtered_link[i]\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        links_pure.append(a['href'])\n",
    "        \n",
    "pattern = re.compile(\"/G-.*\")\n",
    "filtered_link2 = list(set(filter(pattern.match, links_pure)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-envelope",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    در نهایت تمام اطلاعات مربوط به هر دارو را از لینک مربوطه استخراج کرده و تمام صفحات استخراج شده داروها را در یک متغیر ذخیره می‌کنیم.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dimensional-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'https://www.darooyab.ir'\n",
    "\n",
    "for i in range(len(filtered_link2)):\n",
    "    filtered_link2[i] = prefix + filtered_link2[i]\n",
    "    \n",
    "final_pages = []\n",
    "for i in range(len(filtered_link2)):\n",
    "    url = filtered_link2[i]\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    final_pages.append(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-oxygen",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    در این بین ۳ صفحه متفرقه نیز ذخیره می‌شوند که آن هارا شناسایی کرده و به صورت دستی حذف می‌کنیم. مشاهده می‌شود که اطلاعات مربوط به ۱۶۱۷ قلم دارو استخراج شده است.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "consolidated-prairie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1617"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del final_pages[857]\n",
    "del final_pages[859]\n",
    "del final_pages[901]\n",
    "len(final_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-tiffany",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    در این مرحله از صفحات ذخیره شده، یک دیکشنری می‌سازیم که برای هر دارو اطلاعات استخراج شده آن را جدا کرده و مرتب کنیم. هر  entry در این دیکشنری، ۵ دسته   اطلاعات را در خود ذخیره می‌کند که به آن‌ها میپردازیم: \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-allowance",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    اطلاعات با کلید Persian name همان نام فارسی داروی مورد نظر است.\n",
    "    \n",
    "    اطلاعات با کلید English name همان نام انگلیسی داروی مورد نظر است.\n",
    "    \n",
    "    اطلاعات با کلید Martindale classification همان عنوان مربوط به دسته‌بندی مارتیندل داروها است.\n",
    "    \n",
    "    اطلاعات با کلید Treatment classification همان عنوان مربوط به دسته‌بندی درمانی داروها است.\n",
    "    \n",
    "    اطلاعات با کلید Special information اطلاعات تخصصی مربوط به هر دارو است.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "standing-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "myList = []\n",
    "for daroo in range(len(final_pages)):\n",
    "    if len(final_pages[daroo].find_all('div' , class_ =\"JustifyClass\")) == 0:\n",
    "        continue\n",
    "    \n",
    "    if ('+' in str(final_pages[daroo].find_all('h1', class_ = 'EnglishNumericFont')[0].get_text())):\n",
    "        continue\n",
    "        \n",
    "    if ('+' in str(final_pages[daroo].find_all('label', class_= 'EnglishNumericFont')[0].get_text())):\n",
    "        continue\n",
    "        \n",
    "    if str(final_pages[daroo].find_all('h1', class_ = 'EnglishNumericFont')[0].get_text()) == '':\n",
    "        continue\n",
    "        \n",
    "    myDict = {}\n",
    "    temp = ''\n",
    "    for i in range(len(final_pages[daroo].find_all('div' , class_ =\"JustifyClass\"))):\n",
    "        temp = temp + '.' + final_pages[daroo].find_all('div' , class_ =\"JustifyClass\")[i].get_text()\n",
    "        \n",
    "    myDict = {\n",
    "        'Persian Name': str(final_pages[daroo].find_all('h1', class_ = 'EnglishNumericFont')[0].get_text()),\n",
    "        'English Name': str(final_pages[daroo].find_all('label', class_= 'EnglishNumericFont')[0].get_text()),\n",
    "        'Martindale Classification': str(final_pages[daroo].find_all('a', class_ = 'ahref_Generic')[0].get_text()),\n",
    "        'Treatment Classification': str(final_pages[daroo].find_all('label', class_= 'EnglishNumericFont')[1].get_text()),\n",
    "        'Special Information': temp\n",
    "    }\n",
    "    myList.append(myDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-stress",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "     حال داده‌های پردازش شده را به شکل دیکشنری در یک فایل json به نام dataset ذخیره میکنیم که حجم آن 6.31 مگابایت می‌شود.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "after-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset.json', 'w', encoding='utf8') as fout:\n",
    "    json.dump(myList , fout, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-hands",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    حال برای کاوش در متن این اطلاعات، فایل ذخیره شده را باز کرده و تبدیل به دیتافریم می‌کنیم. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sudden-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset.json', 'rb') as json_file:\n",
    "    data = json.load(json_file , encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "atmospheric-substance",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dataframe = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-pricing",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    در ابتدا به عنوان پیش‌پردازش اولیه داده‌ها(ما فقط داده های با کلید Special information را پردازش می‌کنیم زیرا مابقی فیلدها تمیز و درست هستند و نیازی به پیش پردازش ندارند)\n",
    "    \n",
    "    تابعی تعریف کرده که به وسیله زبان های منظم، تمام حروف انگلیسی و فاصله های اضافی و نقطه‌گذاری هارا حذف کند.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "integrated-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess1(text):\n",
    "    text = re.sub(\"[a-zA-Z]\",\"\",text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'[\\t\\n\\d]+','',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-distributor",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    تابع را روی داده ها اعمال کرده و سپس خروجی آن‌ها را به وسیله تابع نرمالایزر کتابخانه هضم، استاندارد‌سازی می‌کنیم.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "catholic-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = hazm.Normalizer()\n",
    "for i in range(len(data_dataframe['Special Information'])):\n",
    "    data_dataframe['Special Information'][i] = preprocess1(data_dataframe['Special Information'][i])\n",
    "    data_dataframe['Special Information'][i] = normalizer.normalize(data_dataframe['Special Information'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-aircraft",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    سپس تمام داده‌ها را به وسیله تابع توکنایزر کتابخانه هضم، توکنایز می‌کنیم.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "outer-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dataframe_tokenize = data_dataframe\n",
    "for i in range(len(data_dataframe_tokenize['Special Information'])):\n",
    "    data_dataframe_tokenize['Special Information'][i] = hazm.word_tokenize(data_dataframe_tokenize['Special Information'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-header",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    حال لیستی از تمام stopwords ها فارسی را بارگذاری کرده و به وسیله آن‌ها، تمام stopwords هارا از بین توکن‌ها حذف می‌کنیم.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "musical-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stopwords.txt\", \"r\" ,encoding=\"utf8\" ) as tf:\n",
    "    stopwords = tf.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "decent-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess2(text):\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "weekly-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dataframe_tokenize['Special Information'] = [preprocess2(y) for y in data_dataframe_tokenize['Special Information']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-estonia",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    سپس به وسیله تابع Lemmatizer کتابخانه هضم، تمام توکن‌هارا ریشه‌یابی می‌کنیم.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "visible-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = hazm.Lemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daily-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dataframe_tokenize['Special Information'] = [[lemmatizer.lemmatize(y) for y in x] for x in data_dataframe_tokenize['Special Information']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-passing",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "    \n",
    "    سپس تمام توکن های مربوط به تمام داروها را در یک متغیر جمع کرده تا روی آن‌ها اعمال آماری را انجام دهیم.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "municipal-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = list(itertools.chain(*data_dataframe_tokenize['Special Information']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-kitchen",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    در این مرحله، ۵۰ توکن پرتکرار از بین تمامی توکن هارا استخراج کرده و نمایش می‌دهیم.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "working-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent = nltk.FreqDist(eval(F\"all_tokens\")).most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "chief-strength",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('دارو', 10162),\n",
       " ('مصرف', 6222),\n",
       " ('افزایش', 5120),\n",
       " ('کاهش', 4185),\n",
       " ('اثرات', 3737),\n",
       " ('صورت', 3409),\n",
       " ('درمان', 3217),\n",
       " ('بیمار', 3165),\n",
       " ('توسط', 2843),\n",
       " ('خون', 2615),\n",
       " ('درد', 2304),\n",
       " ('تداخل', 1996),\n",
       " ('ضد', 1809),\n",
       " ('قلب', 1771),\n",
       " ('کبد', 1655),\n",
       " ('ساعت', 1640),\n",
       " ('گیاه', 1534),\n",
       " ('شد#شو', 1475),\n",
       " ('سیستمیک', 1440),\n",
       " ('ادرار', 1343),\n",
       " ('مهارکننده', 1291),\n",
       " ('پوست', 1279),\n",
       " ('عروق', 1261),\n",
       " ('عفونت', 1193),\n",
       " ('تزریق', 1175),\n",
       " ('عضلانی', 1163),\n",
       " ('استفاده', 1160),\n",
       " ('موضع', 1149),\n",
       " ('اسید', 1078),\n",
       " ('تشدید', 1075),\n",
       " ('مرکزی', 1068),\n",
       " ('اختلال', 1057),\n",
       " ('جذب', 1052),\n",
       " ('سطح', 1044),\n",
       " ('حساسیت', 1039),\n",
       " ('مهار', 1020),\n",
       " ('التهاب', 1013),\n",
       " ('تجویز', 996),\n",
       " ('اعصاب', 979),\n",
       " ('گوارش', 966),\n",
       " ('متابولیسم', 959),\n",
       " ('شایع', 951),\n",
       " ('فشار', 951),\n",
       " ('عوارض', 944),\n",
       " ('احتیاط', 937),\n",
       " ('شدید', 911),\n",
       " ('واکسن', 889),\n",
       " ('دوز', 879),\n",
       " ('سلول', 871),\n",
       " ('طولانی', 871)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-diana",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    سپس تعداد کل کلمات، تعداد کل کلمات یکتا، میانگین طول کلمات و بلندترین کلمه را استخراج کرده و نمایش می‌دهیم.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "relevant-growth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words  364216          \n",
      "Number of unique words 20721           \n",
      "Average word length 5.839575965910339\n",
      "Longest word     نارسیسینایزوکوئرستینایزورامنتینکوئرستینروتینوزیدایزورامنتین\n"
     ]
    }
   ],
   "source": [
    "print ('%-16s' % 'Number of words', '%-16s' % len(all_tokens))\n",
    "print ('%-16s' % 'Number of unique words', '%-16s' % len(set(all_tokens)))\n",
    "avg=np.sum([len(word) for word in all_tokens])/len(all_tokens)\n",
    "print ('%-16s' % 'Average word length', '%-16s' % avg)\n",
    "print ('%-16s' % 'Longest word', '%-16s' % all_tokens[np.argmax([len(word) for word in all_tokens])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-volleyball",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    سپس ۲۰ کلمه پرتکرار در اطلاعات تخصصی هر دارو را استخراج کرده و به عنوان یک ستون جدید برای هر دارو ثبت می‌کنیم. \n",
    "    \n",
    "    با اینکار ما می‌توانیم فقط با نگاه کردن به کلمات پرتکرار هر دارو، از کاربرد و دسته‌بندی و عملکرد هر دارو تا حدودی مطلع شویم.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "supposed-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dataframe_tokenize['Most frequent tokens'] = [nltk.FreqDist(eval(F\"y\")).most_common(20) for y in data_dataframe_tokenize['Special Information']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-continuity",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    با تغییر اولین ورودی تابع iloc میتوانید کلمات پرتکرار هر دارو را مشاهده کنید.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "conventional-width",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('دارو', 17),\n",
       " ('مصرف', 16),\n",
       " ('افزایش', 7),\n",
       " ('ویتامین', 7),\n",
       " ('کاهش', 6),\n",
       " ('پلاکت', 6),\n",
       " ('صورت', 5),\n",
       " ('تیکلوپیدین', 4),\n",
       " ('گوارش', 4),\n",
       " ('جذب', 4),\n",
       " ('غذا', 4),\n",
       " ('میلی', 4),\n",
       " ('گرم', 4),\n",
       " ('روز', 4),\n",
       " ('خون', 4),\n",
       " ('اثرات', 4),\n",
       " ('توسط', 4),\n",
       " ('ضد', 4),\n",
       " ('ای', 4),\n",
       " ('خونریزی', 3)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dataframe_tokenize.iloc[100,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-species",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    در این قسمت سیاق را می‌بینیم.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "concerned-paint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 25 matches:\n",
      "جویز دارو عوارض شیوع عبارتند کبود رنگ پوست اختلال بینایی ویا دوبینی تشنج سرگیجه \n",
      "رو توسط ریتوکسیمببثژ داخل مثانهای تست پوست کوکسیدیوئید ایمیت نیوولومب پیدوتیمود \n",
      "ی خواب رفتگی اندام گذراپوستی خارش راش پوست کهیرگوارشی اسهال تهوع استفراغمشخصات ت\n",
      "ب مرکزی سردرد خوابید#خواب خواب آلودگی پوست افزایش تعریق گوارش خشکی پوست تهوع کاه\n",
      "ب آلودگی پوست افزایش تعریق گوارش خشکی پوست تهوع کاهش اشتها درد شکم استفراغ یبوست\n",
      "ات ناپایدار آژیتاسیون قرار احساس سرما پوست کنده پوست راش پوست خارش کهیر غدد ریز \n",
      "ر آژیتاسیون قرار احساس سرما پوست کنده پوست راش پوست خارش کهیر غدد ریز متابولیسمک\n",
      "ون قرار احساس سرما پوست کنده پوست راش پوست خارش کهیر غدد ریز متابولیسمکاهش وزن ک\n",
      "ط پیمترکسید دی سدیمبثژ داخل مثانه تست پوست کوکسیدیوئید ایمیت لنوگراستیم لیپگفیلگ\n",
      "وره پا بیمار موکوزیت اسهال سم ریوی سم پوست پا کورتیکواستروئیدها کاهش واکنش جلد ت\n",
      "مچنین عصاره ریشه ختم درمان سوختگی زخم پوست استاز گیاه سوزش معده سوء هاضمه زخم مع\n",
      "اغ کاهش اشتها درد شکم یبوست سوء هاضمه پوست راش خارش خون لوکوپنی عصبی عضلانی اسکل\n",
      "لوژی انکولوژی خونریزیعوارض نسبتا شایع پوست ترشح زخم خارش تاول زدن پوستگوارشی درد\n",
      "زیون پارانویا واکنش ازدیاد حساسیت راش پوست اریتم مولتی فر سندرم استونس جانسون کت\n",
      "ستم اعصاب مرکزی سرگیجه سردردپوستی راش پوست خارشگوارشی درد شکم اسهال استفراغکبدی \n",
      "تیک قفسه سینه خارش درد کلیه رینیت راش پوست سنکوپ ناتوان تخلیه مدفوع وزوز گوش لرز\n",
      "رو توسط وینورلبینبثژ داخل مثانهای تست پوست کوکسیدیوئید ایمیت لنوگراستیم لیپگ فیل\n",
      "مت بابینسکی مثبت تشنجپوستی احساس سوزش پوست افزایش تعریق خارشغدد ریز متابولیسم آل\n",
      "یش تعریق کبود نازک اپیدرم قرمزی پوسته پوست قرمزی صورت هایپرپیگمانته آتروفی پوست \n",
      " پوست قرمزی صورت هایپرپیگمانته آتروفی پوست راش پوست سرکوب تست واکنش پوست نازک مو\n",
      "زی صورت هایپرپیگمانته آتروفی پوست راش پوست سرکوب تست واکنش پوست نازک مو کهیر خشک\n",
      " آتروفی پوست راش پوست سرکوب تست واکنش پوست نازک مو کهیر خشکی پوستغدد ریز متابولی\n",
      "بثژ تزریق مثانه کلسیتریول سیستمیک تست پوست کوکسیکوئید ایمیت کورتیکورلین کوزینترو\n",
      "زریق ادم قرمزی هماتوم خونریزی درد راش پوست احساس گرماعصبی عضلانی اسکلت کمردرد در\n",
      "رما ضرب نامنظم قلب تهوع استفراغ قرمزی پوست درد سوزش محل تزریق تعریق گزگز کاهش فش\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(all_tokens)\n",
    "text.concordance('پوست')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "recorded-commissioner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'دارو'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-present",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\"> \n",
    "    \n",
    "    این هم یک شمای کلی از داده‌های ذخیره شده و پردازش ‌های انجام شده بر روی آن‌ها. داده های اصلی را هم می‌توانید در فایل json ذخیره شده مشاهده کنید.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "strong-kazakhstan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Persian Name</th>\n",
       "      <th>English Name</th>\n",
       "      <th>Martindale Classification</th>\n",
       "      <th>Treatment Classification</th>\n",
       "      <th>Special Information</th>\n",
       "      <th>Most frequent tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>سیپروفلوکساسین چشمی</td>\n",
       "      <td>Ciprofloxacin-Ophthalmic</td>\n",
       "      <td>داروهای ضد باکتری</td>\n",
       "      <td>فراورده های چشمی-گوشی-بینی-حلق</td>\n",
       "      <td>[دارو, درمان, عفونت, سطح, چشم, بویژه, زخم, قرن...</td>\n",
       "      <td>[(چشم, 7), (دارو, 4), (قرنیه, 2), (مصرف, 2), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>امیکاسین</td>\n",
       "      <td>Amikacin</td>\n",
       "      <td>داروهای ضد باکتری</td>\n",
       "      <td>داروهای ضد عفونت</td>\n",
       "      <td>[دارو, درمان, عفونت, باکتری, گرم, منفی, مقاوم,...</td>\n",
       "      <td>[(دارو, 15), (سم, 7), (مصرف, 6), (بیمار, 6), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>تتراکائین</td>\n",
       "      <td>Tetracaine</td>\n",
       "      <td>بیحس کننده های موضعی</td>\n",
       "      <td>فراورده های چشمی-گوشی-بینی-حلق</td>\n",
       "      <td>[تتراکائین, ایجاد, حس, موضع, منطق, عنکبوتیه, م...</td>\n",
       "      <td>[(دارو, 14), (مصرف, 9), (موضع, 7), (صورت, 6), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ویتامین ب2</td>\n",
       "      <td>Vitamin B2</td>\n",
       "      <td>عوامل تغذیه ای و ویتامین ها(مکمل ها)</td>\n",
       "      <td>ویتامین ها</td>\n",
       "      <td>[موارد, مصرفپیشگیری, کمبود, ریبو, فلاوین, درما...</td>\n",
       "      <td>[(کمبود, 2), (ریبو, 2), (فلاوین, 2), (موارد, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>برنجاسف</td>\n",
       "      <td>Achillea wilhelmsii C.Koch</td>\n",
       "      <td>داروهای گیاهی</td>\n",
       "      <td>فاقد طبقه بندی فارماکولوژی-درمانی AHFS</td>\n",
       "      <td>[نام, علم, گیاه, خانواده, گیاه, استفاده, اندام...</td>\n",
       "      <td>[(گیاه, 2), (نام, 1), (علم, 1), (خانواده, 1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>نالتروکسون</td>\n",
       "      <td>Naltrexone</td>\n",
       "      <td>آنتی دوت ها،شلات کننده ها و آنتاگونیست ها</td>\n",
       "      <td>داروهای موثر بر سیستم اعصاب مرکزی</td>\n",
       "      <td>[دارو, عنوان, عامل, کمک, درمان, معتادانی, کار,...</td>\n",
       "      <td>[(افزایش, 11), (دارو, 10), (کاهش, 9), (درد, 9)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>اتیدرونیک اسید</td>\n",
       "      <td>Etidronic Acid</td>\n",
       "      <td>داروهای استخوان ساز</td>\n",
       "      <td>عوامل درمانی متفرقه</td>\n",
       "      <td>[دارو, صورت, خوراک, درمان, بیمار, پاژه, پیشگیر...</td>\n",
       "      <td>[(دارو, 13), (استخوان, 12), (کاهش, 8), (کلسیم,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>ماپروتیلین</td>\n",
       "      <td>Maprotiline</td>\n",
       "      <td>داروهای ضد افسردگی</td>\n",
       "      <td>داروهای موثر بر سیستم اعصاب مرکزی</td>\n",
       "      <td>[دارو, بهبود, بیمار, افسردگی, تسکین, تجویز, می...</td>\n",
       "      <td>[(دارو, 20), (مصرف, 16), (اثرات, 7), (نوبت, 6)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>سیمواستاتین</td>\n",
       "      <td>Simvastatin</td>\n",
       "      <td>داروهای قلبی عروقی</td>\n",
       "      <td>داروهای قلبی-عروقی</td>\n",
       "      <td>[سیمواستاتین, عنوان, دارو, کمک, همراه, رژیم, غ...</td>\n",
       "      <td>[(دارو, 16), (مصرف, 14), (افزایش, 9), (درمان, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>کتوتیفن</td>\n",
       "      <td>Ketotifen</td>\n",
       "      <td>گشاد کننده های برونش و داروهای ضد آسم</td>\n",
       "      <td>داروهای آنتی هیستامین</td>\n",
       "      <td>[کتوتیفن, پیشگیر, آسم, کاشت#کار, می‌رودیک, دار...</td>\n",
       "      <td>[(دارو, 8), (اثرات, 5), (کتوتیفن, 4), (افزایش,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1121 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Persian Name                English Name  \\\n",
       "0     سیپروفلوکساسین چشمی    Ciprofloxacin-Ophthalmic   \n",
       "1                امیکاسین                    Amikacin   \n",
       "2               تتراکائین                  Tetracaine   \n",
       "3              ویتامین ب2                  Vitamin B2   \n",
       "4                 برنجاسف  Achillea wilhelmsii C.Koch   \n",
       "...                   ...                         ...   \n",
       "1116           نالتروکسون                  Naltrexone   \n",
       "1117       اتیدرونیک اسید              Etidronic Acid   \n",
       "1118           ماپروتیلین                 Maprotiline   \n",
       "1119          سیمواستاتین                 Simvastatin   \n",
       "1120             کتوتیفن                    Ketotifen   \n",
       "\n",
       "                      Martindale Classification  \\\n",
       "0                             داروهای ضد باکتری   \n",
       "1                             داروهای ضد باکتری   \n",
       "2                          بیحس کننده های موضعی   \n",
       "3          عوامل تغذیه ای و ویتامین ها(مکمل ها)   \n",
       "4                                 داروهای گیاهی   \n",
       "...                                         ...   \n",
       "1116  آنتی دوت ها،شلات کننده ها و آنتاگونیست ها   \n",
       "1117                        داروهای استخوان ساز   \n",
       "1118                         داروهای ضد افسردگی   \n",
       "1119                         داروهای قلبی عروقی   \n",
       "1120      گشاد کننده های برونش و داروهای ضد آسم   \n",
       "\n",
       "                       Treatment Classification  \\\n",
       "0               فراورده های چشمی-گوشی-بینی-حلق    \n",
       "1                              داروهای ضد عفونت   \n",
       "2               فراورده های چشمی-گوشی-بینی-حلق    \n",
       "3                                    ویتامین ها   \n",
       "4      فاقد طبقه بندی فارماکولوژی-درمانی AHFS     \n",
       "...                                         ...   \n",
       "1116          داروهای موثر بر سیستم اعصاب مرکزی   \n",
       "1117                        عوامل درمانی متفرقه   \n",
       "1118          داروهای موثر بر سیستم اعصاب مرکزی   \n",
       "1119                         داروهای قلبی-عروقی   \n",
       "1120                      داروهای آنتی هیستامین   \n",
       "\n",
       "                                    Special Information  \\\n",
       "0     [دارو, درمان, عفونت, سطح, چشم, بویژه, زخم, قرن...   \n",
       "1     [دارو, درمان, عفونت, باکتری, گرم, منفی, مقاوم,...   \n",
       "2     [تتراکائین, ایجاد, حس, موضع, منطق, عنکبوتیه, م...   \n",
       "3     [موارد, مصرفپیشگیری, کمبود, ریبو, فلاوین, درما...   \n",
       "4     [نام, علم, گیاه, خانواده, گیاه, استفاده, اندام...   \n",
       "...                                                 ...   \n",
       "1116  [دارو, عنوان, عامل, کمک, درمان, معتادانی, کار,...   \n",
       "1117  [دارو, صورت, خوراک, درمان, بیمار, پاژه, پیشگیر...   \n",
       "1118  [دارو, بهبود, بیمار, افسردگی, تسکین, تجویز, می...   \n",
       "1119  [سیمواستاتین, عنوان, دارو, کمک, همراه, رژیم, غ...   \n",
       "1120  [کتوتیفن, پیشگیر, آسم, کاشت#کار, می‌رودیک, دار...   \n",
       "\n",
       "                                   Most frequent tokens  \n",
       "0     [(چشم, 7), (دارو, 4), (قرنیه, 2), (مصرف, 2), (...  \n",
       "1     [(دارو, 15), (سم, 7), (مصرف, 6), (بیمار, 6), (...  \n",
       "2     [(دارو, 14), (مصرف, 9), (موضع, 7), (صورت, 6), ...  \n",
       "3     [(کمبود, 2), (ریبو, 2), (فلاوین, 2), (موارد, 1...  \n",
       "4     [(گیاه, 2), (نام, 1), (علم, 1), (خانواده, 1), ...  \n",
       "...                                                 ...  \n",
       "1116  [(افزایش, 11), (دارو, 10), (کاهش, 9), (درد, 9)...  \n",
       "1117  [(دارو, 13), (استخوان, 12), (کاهش, 8), (کلسیم,...  \n",
       "1118  [(دارو, 20), (مصرف, 16), (اثرات, 7), (نوبت, 6)...  \n",
       "1119  [(دارو, 16), (مصرف, 14), (افزایش, 9), (درمان, ...  \n",
       "1120  [(دارو, 8), (اثرات, 5), (کتوتیفن, 4), (افزایش,...  \n",
       "\n",
       "[1121 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dataframe_tokenize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
