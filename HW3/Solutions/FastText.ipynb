{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FastText-Embedding.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "WYufKewGxcU-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embedding Using FastText"
      ],
      "metadata": {
        "id": "svBMTFy-xN04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation and Normalizatoin"
      ],
      "metadata": {
        "id": "WYufKewGxcU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download religious text from course repo\n",
        "!git clone https://github.com/language-ml/course-nlp-ir-1-text-exploring"
      ],
      "metadata": {
        "id": "9qUUK21ZxYLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libs\n",
        "!pip install -Uq camel_tools"
      ],
      "metadata": {
        "id": "9OWrvx4EyFQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all required libs for preprocessing\n",
        "import re\n",
        "from camel_tools.utils.normalize import normalize_unicode\n",
        "from camel_tools.utils.normalize import normalize_alef_maksura_ar\n",
        "from camel_tools.utils.normalize import normalize_alef_ar\n",
        "from camel_tools.utils.normalize import normalize_alef_bw\n",
        "from camel_tools.utils.normalize import normalize_alef_hsb\n",
        "from camel_tools.utils.normalize import normalize_teh_marbuta_ar\n",
        "from camel_tools.utils.dediac import dediac_ar\n",
        "from camel_tools.utils import normalize\n",
        "\n",
        "import tqdm\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "sd_AYfMRxzNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "# Quran\n",
        "religious_dir = \"/content/course-nlp-ir-1-text-exploring/exploring-datasets/religious_text\"\n",
        "\n",
        "df_quran = pd.read_csv(f'{religious_dir}/quranic_data/id_text_with_orthographies.txt', sep='\\t', header=None)\n",
        "verse_complete_dict = pd.Series(df_quran[1].tolist(), index=df_quran[0]).to_dict()\n",
        "\n",
        "# Nahj\n",
        "df_nahj = pd.read_csv(f'{religious_dir}/nahj-al-balaqa/Nahj Al-Balaqa.txt', sep='\\t',header=None)\n",
        "nahj_complete_dict = pd.Series(df_nahj[1].tolist(), index=df_nahj[0]).to_dict()\n",
        "\n",
        "# Sahifa\n",
        "sahife_text=Path(f'{religious_dir}/Saheefa/sahife_sajjadieh.txt').read_text().split('\\n')\n",
        "sahife_complete_dict = [re.sub('[(][۰-۹]+[)]','', item) for item in sahife_text if item.startswith('(')]"
      ],
      "metadata": {
        "id": "7iYdQazHxzAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\"\"\n",
        "          *Quranic Example: {verse_complete_dict['2##186']} \n",
        "          *Nahj Example: {nahj_complete_dict['2##186']} \n",
        "          *Sahifa Example: {sahife_complete_dict[12]}\"\"\")"
      ],
      "metadata": {
        "id": "Di3l05WFyy5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_arabic(sentence):\n",
        "\n",
        "    # Normalize alef variants to 'ا'\n",
        "    sent_norm = normalize_unicode(sentence)\n",
        "    \n",
        "    sent_norm = normalize_alef_bw(sent_norm)\n",
        "    # Normalize alef variants to 'ا'\n",
        "    sent_norm = normalize_alef_ar(sentence)\n",
        "\n",
        "    # Normalize alef maksura 'ى' to yeh 'ي'\n",
        "    sent_norm = normalize_alef_maksura_ar(sent_norm)\n",
        "\n",
        "    # Normalize teh marbuta 'ة' to heh 'ه'\n",
        "    sent_norm = normalize_teh_marbuta_ar(sent_norm)\n",
        "    return dediac_ar(sent_norm)\n",
        "\n",
        "\n",
        "def removeSigns(token):\n",
        "  if token in ['ۖ', 'ۚ', 'ۗ'] or len(token)<3:\n",
        "    return False\n",
        "  else :\n",
        "    return True\n",
        "\n",
        "def itterator(matrix):\n",
        "  for i in range(len(matrix)):\n",
        "    matrix[i] = list(filter(removeSigns, matrix[i]))\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "5bO8OPU50c5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Normalization\n",
        "verse_complete_dict_nrmlz = {k:normalize_arabic(v) for k,v in tqdm.tqdm(verse_complete_dict.items())}\n",
        "nahj_complete_dict_nrmlz = {k:normalize_arabic(v) for k,v in tqdm.tqdm(nahj_complete_dict.items())}\n",
        "sahife_complete_dict_nrmlz = [normalize_arabic(item) for item in tqdm.tqdm(sahife_complete_dict)]"
      ],
      "metadata": {
        "id": "U6YBN6ui0mcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\"\"\n",
        "          *Quranic(pure): {verse_complete_dict['2##186']}\n",
        "          *Quranic(Processed): {verse_complete_dict_nrmlz['2##186']}\n",
        "      \n",
        "          *Nahj(pure): {nahj_complete_dict['2##186']}\n",
        "          *Nahj(Processed): {nahj_complete_dict_nrmlz['2##186']} \n",
        "\n",
        "          *Sahifa(pure): {sahife_complete_dict[12]}\n",
        "          *Sahifa(Processed): {sahife_complete_dict_nrmlz[34]} \"\"\")"
      ],
      "metadata": {
        "id": "-fCrTPVY1D4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Tokenization"
      ],
      "metadata": {
        "id": "O_mn4sn3mtgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Tokenization\n",
        "quranic_tokenized = [sents.split() for sents in tqdm.tqdm(verse_complete_dict_nrmlz.values())]\n",
        "nahj_tokenized = [sents.split() for sents in tqdm.tqdm(nahj_complete_dict_nrmlz.values())]\n",
        "sahife_tokenized = [sents.split() for sents in tqdm.tqdm(sahife_complete_dict_nrmlz)]\n",
        "\n",
        "# Remove Specific Chars and remove word with len<3\n",
        "quranic_tokenized = itterator(quranic_tokenized)\n",
        "nahj_tokenized =itterator(nahj_tokenized)\n",
        "sahife_tokenized = itterator(nahj_tokenized)"
      ],
      "metadata": {
        "id": "kkuDIGYz2Gep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\"\"\n",
        "          Tokenized:\n",
        "            *Quranic Example: {quranic_tokenized[43]}\n",
        "            *Nahj Example: {nahj_tokenized[43]}\n",
        "            *Sahifa Example: {sahife_tokenized[43]}\"\"\")"
      ],
      "metadata": {
        "id": "KxVZ7FBR2TIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FastText Embedding\n",
        "Install required libs and download required data"
      ],
      "metadata": {
        "id": "txTKiIfPNYQE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCZrDwy1PPuA"
      },
      "outputs": [],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download and unzip pretrained arabic model\n",
        "\n",
        "vectorModelDir = '/content/'\n",
        "# ! wget -P /content/ https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ar.300.vec.gz\n",
        "# ! gunzip /content/cc.ar.300.vec.gz"
      ],
      "metadata": {
        "id": "sBwPlxcCT0tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import rquired packages"
      ],
      "metadata": {
        "id": "7jtlU8yMnZYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import numpy as np "
      ],
      "metadata": {
        "id": "TAD9oN3nnKH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load pretrained arabic vector (downlaoded from fasttext data storage)"
      ],
      "metadata": {
        "id": "0dTs8BuvnrdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = KeyedVectors.load_word2vec_format(datapath(f'{vectorModelDir}cc.ar.300.vec'), binary=False)"
      ],
      "metadata": {
        "id": "NOkQun5RVUZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "get vector for each token from pretrained arabic model\n",
        "if each token doesnt exist in model we assign 0 to its vector\n",
        "@param tokens an array of sentence word\n",
        "@return an array of tuples with format (token, vector)\n",
        "\"\"\"\n",
        "def W2V4corpus(token,models):\n",
        "  w2vToken = token\n",
        "  k=0 \n",
        "  for i in range(len(token)):\n",
        "    for j in range(len(token[i])):\n",
        "      word = token[i][j]\n",
        "      models = model\n",
        "      if word in models:\n",
        "        w2vToken[i][j] = (word,models[word])\n",
        "      else:\n",
        "        # list of words that dosent exist in the vector\n",
        "        print(word)\n",
        "        k=k+1\n",
        "        w2vToken[i][j] = (word,0)\n",
        "  print(f'number of words that dosent exist in the pretrained fasttext model: {k}')\n",
        "  return w2vToken\n",
        "\n",
        "quranic_w2v = W2V4corpus(quranic_tokenized,model)\n",
        "nahj_w2v = W2V4corpus(nahj_tokenized,model)\n",
        "# sahifeh_w2v = W2V4corpus(sahife_tokenized,model)"
      ],
      "metadata": {
        "id": "ugNCWUyodMed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate avg of word vectors in sentence \n",
        "def calculateSentenceVector(wordVector):\n",
        "  return np.mean( np.array(wordVector), axis=0 )\n",
        "\n",
        "# convert doc to vector\n",
        "def doc2vec(corpus):\n",
        "  temp = []\n",
        "  for i in range(len(corpus)):\n",
        "    temp.append(calculateSentenceVector([l[1] for l in corpus[i]]))\n",
        "  return temp"
      ],
      "metadata": {
        "id": "TGxf63px7_HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verse_complete_dict_nrmlze=[]\n",
        "verse_complete_dict_nrmlze.append(list(verse_complete_dict_nrmlz.values()))\n",
        "\n",
        "nahj_complete_dict_nrmlze=[]\n",
        "nahj_complete_dict_nrmlze.append(list(nahj_complete_dict_nrmlz.values()))\n",
        "\n",
        "# sahife_complete_dict_nrmlze=[]\n",
        "# sahife_complete_dict_nrmlze.append(list(sahife_complete_dict_nrmlz.values()))"
      ],
      "metadata": {
        "id": "wiHShjL2rwJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verse_complete_dict_nrmlze.append(doc2vec(quranic_w2v))\n",
        "nahj_complete_dict_nrmlze.append(doc2vec(nahj_w2v))\n",
        "# sahife_complete_dict_nrmlze.append()"
      ],
      "metadata": {
        "id": "nPN_c0O6ExGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a test vector query\n",
        "query = [-0.0417    ,  0.01735   , -0.02275   ,  0.0172    ,  0.18415   ,\n",
        "        0.002525  , -0.0532    ,  0.10465   ,  0.003075  , -0.12132499,\n",
        "        0.046725  , -0.15392499,  0.0511    ,  0.036025  , -0.0806    ,\n",
        "        0.0206    , -0.014075  ,  0.0328    ,  0.0699    , -0.0173    ,\n",
        "       -0.05935   , -0.0393    , -0.011925  , -0.042025  ,  0.007625  ,\n",
        "        0.028275  ,  0.017     , -0.017     ,  0.0067    , -0.003225  ,\n",
        "       -0.04735   ,  0.0046    ,  0.0737    , -0.044025  , -0.1193    ,\n",
        "        0.01255   ,  0.008     , -0.011275  ,  0.065875  , -0.00385   ,\n",
        "       -0.0565    , -0.004     , -0.04055   ,  0.041325  ,  0.072025  ,\n",
        "       -0.053225  , -0.009     ,  0.006375  , -0.03895   ,  0.00415   ,\n",
        "        0.010825  ,  0.051175  ,  0.027925  ,  0.0647    , -0.0468    ,\n",
        "        0.00615   , -0.05085   ,  0.06835   , -0.046975  ,  0.008875  ,\n",
        "       -0.076475  , -0.0143    ,  0.12365   , -0.007675  , -0.04905   ,\n",
        "       -0.060775  , -0.071025  ,  0.018975  , -0.09615   ,  0.006625  ,\n",
        "        0.00425   ,  0.016325  ,  0.02305   ,  0.102375  ,  0.0041    ,\n",
        "        0.035475  ,  0.033675  , -0.034625  , -0.019225  , -0.0075    ,\n",
        "        0.0188    ,  0.01985   ,  0.01845   ,  0.09330001,  0.04525   ,\n",
        "        0.063225  , -0.0042    ,  0.030125  , -0.00615   ,  0.0305    ,\n",
        "       -0.048275  , -0.037725  , -0.15822499, -0.057425  ,  0.032125  ,\n",
        "        0.034575  , -0.012625  ,  0.0177    , -0.043325  , -0.000375  ,\n",
        "       -0.0091    , -0.016325  ,  0.051625  , -0.01885   , -0.028675  ,\n",
        "       -0.0035    ,  0.100725  ,  0.01365   ,  0.0144    , -0.09635   ,\n",
        "        0.024525  ,  0.0395    , -0.0642    , -0.033275  ,  0.025525  ,\n",
        "       -0.0359    ,  0.039425  ,  0.057125  , -0.012325  , -0.00725   ,\n",
        "       -0.03285   ,  0.0121    , -0.054225  ,  0.028075  , -0.047875  ,\n",
        "       -0.032     , -0.022275  ,  0.01855   , -0.0538    , -0.011225  ,\n",
        "        0.032875  ,  0.05465   , -0.06935   , -0.028425  ,  0.061475  ,\n",
        "        0.1463    , -0.004275  , -0.012375  , -0.029775  , -0.032975  ,\n",
        "        0.001125  ,  0.015525  , -0.002075  , -0.05595   ,  0.061825  ,\n",
        "        0.034425  ,  0.07555   ,  0.002325  ,  0.0076    , -0.0675    ,\n",
        "       -0.0176    , -0.007025  ,  0.0332    ,  0.006175  ,  0.03495   ,\n",
        "        0.04405   , -0.018925  ,  0.06587499,  0.01975   , -0.07065   ,\n",
        "        0.01415   , -0.05730001, -0.18477501,  0.044975  , -0.04485   ,\n",
        "       -0.013275  ,  0.004525  , -0.024275  , -0.044125  ,  0.14465   ,\n",
        "        0.0218    ,  0.096975  , -0.028325  , -0.0477    , -0.033025  ,\n",
        "        0.022375  , -0.09285   , -0.020825  , -0.024925  ,  0.01135   ,\n",
        "        0.007175  , -0.00945   ,  0.0219    , -0.05575   ,  0.011525  ,\n",
        "       -0.004325  ,  0.002     ,  0.0245    ,  0.03255   ,  0.1248    ,\n",
        "       -0.01445   ,  0.002075  , -0.047775  ,  0.024975  ,  0.0366    ,\n",
        "        0.005375  ,  0.01735   ,  0.0441    , -0.056575  , -0.07214999,\n",
        "        0.069775  ,  0.041775  ,  0.02095   ,  0.005     ,  0.01585   ,\n",
        "        0.1201    ,  0.0442    ,  0.03355   , -0.0055    ,  0.0032    ,\n",
        "       -0.014375  ,  0.062875  ,  0.12917499,  0.014275  , -0.008225  ,\n",
        "        0.043525  , -0.01255   , -0.05225   , -0.02575   ,  0.022625  ,\n",
        "        0.01995   ,  0.13445   , -0.028725  ,  0.040375  ,  0.082675  ,\n",
        "       -0.00955   ,  0.02225   ,  0.033675  ,  0.014525  , -0.065625  ,\n",
        "        0.098525  , -0.0844    , -0.0007    ,  0.0607    , -0.0512    ,\n",
        "       -0.02285   , -0.00135   ,  0.077825  , -0.012025  , -0.0123    ,\n",
        "       -0.00545   , -0.09477501,  0.03585   ,  0.016825  , -0.162875  ,\n",
        "        0.0461    ,  0.0363    , -0.079075  ,  0.012575  , -0.07435   ,\n",
        "        0.035275  ,  0.01915   , -0.024175  , -0.07385   ,  0.03185   ,\n",
        "        0.003925  ,  0.025075  ,  0.000625  ,  0.012675  ,  0.020825  ,\n",
        "       -0.01565   ,  0.0155    , -0.04005   ,  0.0621    , -0.13335   ,\n",
        "       -0.007175  , -0.019975  ,  0.032875  , -0.0837    ,  0.027225  ,\n",
        "       -0.001075  , -0.07555   , -0.054675  ,  0.0209    , -0.07645   ,\n",
        "       -0.09375   , -0.001375  , -0.07345   , -0.03495   , -0.061125  ,\n",
        "        0.037675  , -0.10332499,  0.001775  ,  0.02775   ,  0.023175  ,\n",
        "        0.03305   ,  0.044     ,  0.0097    , -0.017775  , -0.007875  ,\n",
        "       -0.01      ,  0.0012    , -0.031425  , -0.01365   ,  0.01945   ,\n",
        "        0.0583    ,  0.11995   ,  0.003475  ,  0.003075  , -0.0917    ]"
      ],
      "metadata": {
        "id": "Ai8HD1dm-VCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "calculate similarity between input query and all words in vecList using cosine similarity\n",
        "@param query the input query vector\n",
        "@param vecList a list of vectors(words)\n",
        "@return a list of similarity rank\n",
        "\"\"\"\n",
        "\n",
        "def calculateSimilarity(qurey, vecList):\n",
        "  temp=[]\n",
        "  k=0\n",
        "  for i in vecList[1]:\n",
        "    print(k)\n",
        "    k = k+1\n",
        "    temp.append(cosine_similarity([qurey], [i]))\n",
        "  return temp\n",
        "\n",
        "\"\"\"\n",
        "return similarity matrix\n",
        "@param quran if true search in quranic verse to find similar verse\n",
        "@param nahj if true search in nahj ol balaghe verse to find similar verse\n",
        "@param sahifa if true search in sahifa verse to find similar verse\n",
        "\"\"\"  \n",
        "def mostSimilar(queryVector, quran=True, nahj=False, sahifa=False):\n",
        "  similarVector=[]\n",
        "  if quran:\n",
        "    similarVector.append(calculateSimilarity(queryVector, verse_complete_dict_nrmlze))\n",
        "  if nahj:\n",
        "    similarVector.append(calculateSimilarity(queryVector, nahj_complete_dict_nrmlze))\n",
        "  if sahifa:\n",
        "    similarVector.append(calculateSimilarity(queryVector, nahj_complete_dict_nrmlze))\n",
        "  return similarVector"
      ],
      "metadata": {
        "id": "LxLvKX6P5f0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a list for similarity between input query and all sentence\n",
        "similarity = mostSimilar(query, quran=True)"
      ],
      "metadata": {
        "id": "3FWYqxZ_8UO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sort similarity and select top 10\n",
        "sortedSimilarity = sorted(similarity, key=lambda x: x[1])\n",
        "sortedSimilarity[:10]"
      ],
      "metadata": {
        "id": "XgcP62_mDd5u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}